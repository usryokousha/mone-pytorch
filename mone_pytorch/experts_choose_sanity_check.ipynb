{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from layers.routing import ExpertsChooseRouter, ExpertsChooseMaskedRouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test tensor of shape (batch_size, seq_len, hidden_size)\n",
    "x = torch.randn(1, 20, 128)\n",
    "capacity = 20\n",
    "num_experts = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expert_gate shape: torch.Size([1, 4, 20]), expert_indices shape: torch.Size([1, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "# create a router\n",
    "router = ExpertsChooseRouter(num_experts=num_experts, dim=128)\n",
    "\n",
    "# apply the router to the input tensor\n",
    "expert_gate, expert_indices = router(x, capacity)\n",
    "\n",
    "print(f\"expert_gate shape: {expert_gate.shape}, expert_indices shape: {expert_indices.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispatch_mask shape: torch.Size([1, 20, 4, 20]), combine_array shape: torch.Size([1, 20, 4, 20])\n"
     ]
    }
   ],
   "source": [
    "masked_router = ExpertsChooseMaskedRouter(num_experts=num_experts, dim=128)\n",
    "# copy weights from router to masked router\n",
    "masked_router.router_weights.weight = router.router_weights.weight\n",
    "masked_router.router_weights.bias = router.router_weights.bias\n",
    "\n",
    "dispatch_mask, combine_array = masked_router(x, capacity)\n",
    "\n",
    "print(f\"dispatch_mask shape: {dispatch_mask.shape}, combine_array shape: {combine_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_selected_advanced shape: torch.Size([1, 4, 20, 128]), x_selected_masked shape: torch.Size([1, 4, 20, 128])\n",
      "x_selected_advanced == x_selected_masked: True\n"
     ]
    }
   ],
   "source": [
    "from layers.expert_choose_linear import gather_experts\n",
    "\n",
    "# test expert choose contract using advanced indexing\n",
    "x_selected_advanced = gather_experts(x, expert_indices)\n",
    "\n",
    "# now do equivalent with masking\n",
    "x_selected_masked = torch.einsum(\"bt...,btec->bec...\", x, dispatch_mask)\n",
    "\n",
    "print(f\"x_selected_advanced shape: {x_selected_advanced.shape}, x_selected_masked shape: {x_selected_masked.shape}\")\n",
    "\n",
    "# now check if the two are the same\n",
    "print(f\"x_selected_advanced == x_selected_masked: {torch.allclose(x_selected_advanced, x_selected_masked)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_expert_advanced shape: torch.Size([1, 4, 20, 32]), x_expert_masked shape: torch.Size([1, 4, 20, 32])\n",
      "x_expert_advanced == x_expert_masked: True\n"
     ]
    }
   ],
   "source": [
    "# create a linear layer\n",
    "linear = nn.Linear(128, 128)\n",
    "\n",
    "# Expert computation\n",
    "x_expert_advanced = torch.einsum(\"beci,eoi->beco\", x_selected_advanced, torch.reshape(linear.weight, (num_experts, 128 // num_experts, 128)))\n",
    "x_expert_masked = torch.einsum(\"beci,eoi->beco\", x_selected_masked, torch.reshape(linear.weight, (num_experts, 128 // num_experts, 128)))\n",
    "\n",
    "print(f\"x_expert_advanced shape: {x_expert_advanced.shape}, x_expert_masked shape: {x_expert_masked.shape}\")\n",
    "\n",
    "print(f\"x_expert_advanced == x_expert_masked: {torch.allclose(x_expert_advanced, x_expert_masked, atol=1e-6)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "# now let's do the same with scatter\n",
    "x_expanded = torch.einsum(\"beci,eoi->beco\", x_expert_advanced, torch.reshape(linear.weight, (num_experts, 128, 128 // num_experts)))\n",
    "print(x_expanded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 128])\n"
     ]
    }
   ],
   "source": [
    "from layers.expert_choose_linear import scatter_experts\n",
    "\n",
    "x_reduced_advanced = scatter_experts(x_expanded * expert_gate.unsqueeze(-1), expert_indices, capacity)\n",
    "\n",
    "print(x_reduced_advanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 128])\n",
      "x_reduced_advanced == x_reduced_masked: True\n"
     ]
    }
   ],
   "source": [
    "x_reduced_masked = torch.einsum(\n",
    "            \"bec...,btec->bt...\", x_expanded, combine_array\n",
    "        )\n",
    "\n",
    "print(x_reduced_masked.shape)\n",
    "\n",
    "print(f\"x_reduced_advanced == x_reduced_masked: {torch.allclose(x_reduced_advanced, x_reduced_masked, atol=1e-6)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
